{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perspective Projection\n",
    "* When we project an object in the real world onto a sensor\n",
    "![](img/CameraProjection.png)\n",
    "  * the image on the sensor is a miniature version of the value in the sensor\n",
    "  * A particular point X,Y,Z will get mapped onto the sensor as\n",
    "$$(X', Y', Z') = (X\\frac{-d}{Z},Y\\frac{-d}{Z},-d)$$\n",
    "  * This is a non-linear operation, as farther points, get divided by different Zs\n",
    "  * So the math now gets problematic\n",
    "\n",
    "### Homogenous Coordinates\n",
    "* Adding another dimension to resolve the issue\n",
    "$$(\\frac{x}{w}, \\frac{y}{w}, \\frac{z}{w}) =>\n",
    "\\left[\n",
    "\\begin{array}\\\\\n",
    "x \\\\\n",
    "y \\\\\n",
    "z \\\\\n",
    "w \\\\\n",
    "\\end{array}\n",
    "\\right]$$\n",
    "* So now we can take the projected values and work the math and not worry about the transformation until we need to render\n",
    "$$\\left[\n",
    "\\begin{array}\\\\\n",
    "1 & 0 & 0 & 0 \\\\\n",
    "0 & 1 & 0 & 0 \\\\\n",
    "0 & 0 & \\frac{1}{f} & 0 \\\\\n",
    "\\end{array}\n",
    "\\right]\\left[\n",
    "\\begin{array}\\\\\n",
    "x \\\\\n",
    "y \\\\\n",
    "z \\\\\n",
    "1 \\\\\n",
    "\\end{array}\n",
    "\\right] = \\left[\n",
    "\\begin{array}\\\\\n",
    "x \\\\\n",
    "y \\\\\n",
    "\\frac{z}{f}\\\\\n",
    "\\end{array}\n",
    "\\right] => (x\\frac{f}{z},y\\frac{f}{z}) => (u,v)$$\n",
    "  * The conversion to the projected co-ordinate system can occur only at the very end when we want to render or do a image manipulation operation\n",
    "  * This is also scale invariant. Multiplying the original operation by a constant does not impact the final output\n",
    "  \n",
    "#### Example Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Real World Co-ordinates: ', [4000.0, 10000.0, 50000.0])\n",
      "('Homogenous Co-ordinates: ', array([  4000.,  10000.,    500.]))\n",
      "('Image Co-ordinates: ', [8.0, 20.0])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Simple projection function\n",
    "def Homogenous2Image(_v):\n",
    "    return [_v[0]/_v[2],_v[1]/_v[2]]\n",
    "\n",
    "def ProjectOntoImage(_P, _f):\n",
    "    ProjMat = np.zeros((3,4),dtype = np.float)\n",
    "    ProjMat[0][0] = ProjMat[1][1] = 1.0\n",
    "    ProjMat[2][2] = (1/_f)\n",
    "    \n",
    "    tempP = np.append(_P, 1.0)\n",
    "    \n",
    "    return np.matmul(ProjMat, tempP)\n",
    "    \n",
    "# Point in the real world in mm\n",
    "P = [4000.0, 10000.0, 50000.0]\n",
    "# Focal length\n",
    "f = 100.0\n",
    "\n",
    "print (\"Real World Co-ordinates: \",P)\n",
    "print (\"Homogenous Co-ordinates: \",ProjectOntoImage(P, f))\n",
    "print (\"Image Co-ordinates: \",Homogenous2Image(ProjectOntoImage(P, f)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Properties\n",
    "* A point / line / Polygon on the real world gets mapped to a point / line and polygon on the perspective projection respectively\n",
    "* Almost all parallel lines in the real world, meet at a \"vanishing\" point in the projection (think of a road / railway line)\n",
    "* All lines in the same plane, converge at various vanishing points that are co-linear (as in the vanishing points) line on a single line. This line is the horizon.\n",
    "\n",
    "\n",
    "## Other projection models\n",
    "* Orthographic Projection\n",
    "  * Where we model telephoto lens, where all the rays are coming in parallel to each other\n",
    "  * So there is no transformation, it's just the exact same image on the sensor and it's scaled (X & Y) down to the sensor size\n",
    "  * Important thing is that Z is not used\n",
    "* Weak projection\n",
    "  * Here we assume that all the real world objects that we want to map is at a constant depth Z<sub>0</sub>\n",
    "  * Rest remains the same as the Homogenous Perspective\n",
    "  * This can be used where the X & Y scale of the object is so huge, that the depth variations within the object does not matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
