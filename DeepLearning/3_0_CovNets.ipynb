{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CovNets\n",
    "## Rationale\n",
    "Typical NN do not use the dimensional properties of the problem, such as say colors, or the fact that images are 2D or that videos are 3D or that music has multiple channels. All the information is flattened and given to the network. CNNs are created to exploit this detail to achieve better results.\n",
    "\n",
    "A discrete convolution is a linear transformation that preserves this notion of ordering. It is sparse (only a few input units contribute to a given output unit) and reuses parameters (the same weights are applied to multiple locations in the input).\n",
    "\n",
    "## Translation Invariance\n",
    "A property where we explicitly tell the network, that the position of the object within the image does not matter. Would be tremendously useful for all ADAS applications…\n",
    "\n",
    "This is implemented using weight sharing, where the various types of images that are similar will share weights…\n",
    "\n",
    "## CovNets\n",
    "![ConvNets](img/Conv.png)\n",
    "* Take a small NN and run it along the entire image space. This gives us the out which would have depth of k and width and height reduced from the original space. So the \n",
    "* This results in h & w progressively decreasing while the depth increases, hence a convolutional pyramid\n",
    "![ConvPyramids](img/ConvPyramid.png)\n",
    "* Have to consider the edge,\n",
    "  * Same padding is when we pad with 0s and go till the edge\n",
    "  * Valid padding is when we don't fall off the edge at all\n",
    "* At the end of the Cov pyramid, you feed the data to a regular deep net classifier… That's it…\n",
    "\n",
    "## Advance CovNets\n",
    "1. Pooling\n",
    "\tHaving a large stride, will make the system lose a lot of information. So in pooling, we have a low stride, but we apply pooling (compressing) on the output of the convolution to reduce the size. Many types of pooling\n",
    "  a. Max Pooling\n",
    "\t Simply take y = max(xi) of all surrounding neighbours\n",
    "\t This is surprisingly accurate and is parameter free\n",
    "\t But more expensive and lots of hyper parameters (such as pooling stride, pooling size to tune)\n",
    "  b. Average Pooling\n",
    "     Mean instead of max\n",
    "2. 1x1 convolutions\n",
    "\tAdd a 1x1 convolution after each patch operation to add a mini deep nn for each convolution output\n",
    "![1x1 Convolutions](img/Conv1x1.png)\n",
    "\tVery cheap and gives a lot of parameters to the model so allows the model to generalize well\n",
    "\t\n",
    "3. Inception Modules\n",
    "Combine all the above features into the CovNet to result in must better features while not being costly at all. It results in a model that is lot more complicated, but results in much better performance.\n",
    "![Inception](img/ConvInception.png)\n",
    "\n",
    "## Resources\n",
    "https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/\n",
    "https://arxiv.org/pdf/1502.02766v3.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
